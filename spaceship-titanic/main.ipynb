{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, auc, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./train.csv')\n",
    "test_data = pd.read_csv('./test.csv')\n",
    "display(train_data.shape)\n",
    "display(test_data.shape)\n",
    "dfs = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    print(f\"dataset has {df.shape[1]} and {df.shape[0]} examples\")\n",
    "    summary = pd.DataFrame(index=df.columns)\n",
    "    summary['Missing'] = df.isna().sum().values\n",
    "    summary['Unique_values'] = df.nunique().values\n",
    "    summary['Duplicated'] = df.duplicated().sum()\n",
    "    summary['Types'] = df.dtypes\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    passengerId_split = df.PassengerId.str.split('_')\n",
    "    # type(passengerId_split)\n",
    "    df['group_id'] = passengerId_split.str[0]\n",
    "    df['group_id'] = df['group_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    tmp_df = df[df['HomePlanet'].notna()]\n",
    "    tmp_df = tmp_df.groupby('group_id').apply(lambda x: x['HomePlanet'].unique()[0])\n",
    "    df['HomePlanet'] = df.apply(\n",
    "        lambda row: ((tmp_df[row['group_id']] if row['group_id'] in tmp_df.index else np.NaN) \n",
    "                    if pd.isnull(row['HomePlanet']) else row['HomePlanet']), axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    tmp = df['HomePlanet'].value_counts()\n",
    "    v = tmp.index # ['Earth', 'Europa', 'Mars']\n",
    "    p = tmp.values \n",
    "    p = p/sum(p)\n",
    "    df.loc[df['HomePlanet'].isna(), 'HomePlanet'] = np.random.choice(v, df['HomePlanet'].isna().sum(), p=p)\n",
    "    df['HomePlanet'] = df['HomePlanet'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df['total_spend'] = df['RoomService'] + df['FoodCourt'] + \\\n",
    "                                df['ShoppingMall'] + df['Spa'] + df['VRDeck']\n",
    "    df['any_spend'] = np.where(df['total_spend'] > 0, True, False)\n",
    "    spend_criteria = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df['CryoSleep'] = df['CryoSleep'].astype(bool)\n",
    "    df.loc[df['CryoSleep'] == True][spend_criteria].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    for criteria in spend_criteria:\n",
    "        df.loc[df['CryoSleep'] == True & df[criteria].isna(), criteria] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.loc[df['any_spend'] == True & df['CryoSleep'].isna(), 'CryoSleep'] = False\n",
    "    df['CryoSleep'] = df['CryoSleep'].astype(int)\n",
    "    df['CryoSleep'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.loc[df['CryoSleep'] == 1 & df['total_spend'].isna(), 'total_spend'] = 0\n",
    "    df['total_spend'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    tmp_df = df[df['Cabin'].notna()]\n",
    "    tmp_df = tmp_df.groupby('group_id').apply(lambda x: x['Cabin'].unique()[0])\n",
    "    df['Cabin'] = df.apply(\n",
    "        lambda row: ((tmp_df[row['group_id']] if row['group_id'] in tmp_df.index else np.NaN) \n",
    "                    if pd.isnull(row['Cabin']) else row['Cabin']), axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    tmp = df['Cabin'].apply(lambda x: x.split('/') if type(x) != float else ['-1', '-1', '-1']).to_list()\n",
    "    tmp = np.array(tmp)\n",
    "    df['cabin_deck'] = tmp[:, 0]\n",
    "    df['cabin_num'] = tmp[:, 1]\n",
    "    df['cabin_side'] = tmp[:, 2]\n",
    "    df.drop(columns = 'Cabin', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.loc[df['cabin_deck']=='-1', 'cabin_deck'] = np.random.choice(['F', 'G'], \n",
    "                                                    sum(df['cabin_deck']=='-1'), p=[0.5, 0.5])\n",
    "    df['cabin_deck'] = df['cabin_deck'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    # df['cabin_num'].value_counts()\n",
    "    df['cabin_num'] = df['cabin_num'].astype(int)\n",
    "    calculated_mean = df[df['cabin_num'] != -1]['cabin_num'].mean()\n",
    "    df.loc[df['cabin_num'] == -1, 'cabin_num'] =  calculated_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.loc[df['cabin_side']=='-1', 'cabin_side'] = np.random.choice(['S', 'P'],\n",
    "                                                    sum(df['cabin_side']=='-1'), p=[0.5, 0.5])\n",
    "    df['cabin_side'] = df['cabin_side'].map({'S':0, 'P':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df.loc[df['Destination'].isna(), 'Destination'] = np.random.choice(\n",
    "        ['TRAPPIST-1e', '55 Cancri e', 'PSO J318.5-22'], sum(df['Destination'].isna()),\n",
    "        p = [0.5, 0.3, 0.2]\n",
    "    )\n",
    "    df['Destination'] = df['Destination'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Age'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_age = df['Age'].mean()\n",
    "# std_age = df['Age'].std()\n",
    "# is_null = df['Age'].isnull().sum()\n",
    "# random_sample = np.random.uniform(mean_age - std_age, mean_age + std_age, size=is_null)\n",
    "# df.loc[df['Age'].isna(), 'Age'] = random_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    # df['Destination'].fillna(df['Destination'].mode()[0], inplace=True)\n",
    "    df['VIP'].fillna(df['VIP'].mode()[0], inplace=True)\n",
    "    df['VIP'] = df['VIP'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "    df['PassengerId'] = df['PassengerId'].astype(str)\n",
    "    df.drop(columns='total_spend', inplace=True)\n",
    "    df.drop(columns='any_spend', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inefficient code, takes too much time to run \n",
    "# df['group_size'] = df['group_id'].map(lambda x: df['group_id'].value_counts()[x])\n",
    "# df['group_size'] = df['group_size'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    group_size = df['group_id'].value_counts().to_dict()\n",
    "    df['group_size'] = df['group_id'].apply(lambda x: group_size[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'group_size']\n",
    "quant_pipeline = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('imputer', KNNImputer(n_neighbors=7))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df[quant_features] = quant_pipeline.fit_transform(df[quant_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train_data.select_dtypes(include='category').columns.to_list()\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, pd.get_dummies(train_data[cat_features], drop_first=True)], axis=1)\n",
    "train_data.drop(columns=cat_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data, pd.get_dummies(test_data[cat_features], drop_first=True)], axis=1)\n",
    "test_data.drop(columns=cat_features, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# summary(train_data)\n",
    "# summary(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop(['Name', 'PassengerId', 'Transported'], axis=1)\n",
    "y_train = train_data['Transported']\n",
    "display(x_train.shape)\n",
    "display(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop(['Name', 'PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators' : [100, 200, 400],\n",
    "    'learning_rate' : [0.01, 0.1, 0.3, 0.5, 0.9],\n",
    "    'max_depth' : range(3, 8, 2),\n",
    "    'min_child_weight' : range(1, 6, 2),\n",
    "    'gamma' : [i/10.0 for i in range(1, 5)],\n",
    "    'subsample' : [i/10.0 for i in range(6, 10)],\n",
    "    'colsample_bytree' : [i/10.0 for i in range(6, 10)],\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch = GridSearchCV(estimator=xgb.XGBClassifier(objective='binary:logistic', n_jobs=-1), \n",
    "                       param_grid=params, cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSearch.best_params_, gSearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators =10, seed = 123)\n",
    "# xg_cl.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_anal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
